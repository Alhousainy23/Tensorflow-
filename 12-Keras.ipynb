{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txSCEQ_OMEEI"
      },
      "source": [
        "# 1- Using Keras With Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZxA3gZ3MBtd",
        "outputId": "f5f5d941-6ba2-49ba-fc95-7a47c7868503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X Train Shape is :  (60000, 28, 28)\n",
            "X Train  is :  [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13  25 100\n",
            "  122   7   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  33 151 208 252 252\n",
            "  252 146   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  40 152 244 252 253 224 211\n",
            "  252 232  40   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  15 152 239 252 252 252 216  31  37\n",
            "  252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  96 252 252 252 252 217  29   0  37\n",
            "  252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 181 252 252 220 167  30   0   0  77\n",
            "  252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  26 128  58  22   0   0   0   0 100\n",
            "  252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 157\n",
            "  252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 110 121 122 121 202\n",
            "  252 194   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  10  53 179 253 253 255 253 253\n",
            "  228  35   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   5  54 227 252 243 228 170 242 252 252\n",
            "  231 117   6   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   6  78 252 252 125  59   0  18 208 252 252\n",
            "  252 252  87   7   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   5 135 252 252 180  16   0  21 203 253 247 129\n",
            "  173 252 252 184  66  49  49   0   0   0]\n",
            " [  0   0   0   0   0   3 136 252 241 106  17   0  53 200 252 216  65   0\n",
            "   14  72 163 241 252 252 223   0   0   0]\n",
            " [  0   0   0   0   0 105 252 242  88  18  73 170 244 252 126  29   0   0\n",
            "    0   0   0  89 180 180  37   0   0   0]\n",
            " [  0   0   0   0   0 231 252 245 205 216 252 252 252 124   3   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 207 252 252 252 252 178 116  36   4   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  13  93 143 121  23   6   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "---------------------------------------- ---------------------------------------- \n",
            "X Test Shape is :  (10000, 28, 28)\n",
            "X Test  is :  [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  77 254\n",
            "  107   3   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  19 227 254\n",
            "  254   9   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  81 254 254\n",
            "  165   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   7 203 254 254\n",
            "   73   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  53 254 254 250\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 134 254 254 180\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 196 254 248  48\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  58 254 254 237   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 111 254 254 132   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 163 254 238  28   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  60 252 254 223   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  79 254 254 154   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 163 254 238  53   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  28 252 254 210   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  86 254 254 131   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 105 254 234  20   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 175 254 204   5   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   5 211 254 196   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   3 158 254 160   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  26 157 107   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "---------------------------------------- ---------------------------------------- \n",
            "y Train Shape is :  (60000,)\n",
            "y Train is :  2\n",
            "---------------------------------------- ---------------------------------------- \n",
            "y Test Shape is :  (10000,)\n",
            "y Test  is :  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf \n",
        "#Read Mnist Data\n",
        "mnist = tf.compat.v1.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "print('X Train Shape is : ' , x_train.shape)\n",
        "print('X Train  is : ' , x_train[5])\n",
        "print('---------------------------------------- '*2)\n",
        "print('X Test Shape is : ' , x_test.shape)\n",
        "print('X Test  is : ' , x_test[5])\n",
        "print('---------------------------------------- '*2)\n",
        "print('y Train Shape is : ' , y_train.shape)\n",
        "print('y Train is : ' , y_train[5])\n",
        "print('---------------------------------------- '*2)\n",
        "print('y Test Shape is : ' , y_test.shape)\n",
        "print('y Test  is : ' , y_test[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bChMzBgLWoQs"
      },
      "source": [
        "# 2- Create Neural Network Object Just Only Not Contain(Input - Hideen - Output ) Layers & Neurons  for each layer & Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PKirKsV8M1YX"
      },
      "outputs": [],
      "source": [
        "model = tf.compat.v1.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cWUoOk6eXyI"
      },
      "source": [
        "# 3- Create Hidden Layer In Nerual Networks\n",
        "# (I Need Create 4 Hidden Layers In Nerual Networks) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y5_9YRKwXLcn"
      },
      "outputs": [],
      "source": [
        "# First Hidden Layer\n",
        "model.add(tf.compat.v1.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "# activation =  softmax  , elu , relu , tanh , sigmoid , linear\n",
        "#Second Hidden Layer  ==> model.add(tf.compat.v1.keras.layers.Dense(350, activation=tf.nn.tanh))\n",
        "#Third Hidden Layer ==> model.add(tf.compat.v1.keras.layers.Dense(230, activation=tf.nn.softmax))\n",
        "#Fourth Hidden Layer ==>model.add(tf.compat.v1.keras.layers.Dense(128, activation=tf.nn.elu))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFcD-723xEVC"
      },
      "source": [
        "# 4-Make Deliberate projection of some neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f-_uqxwWekA6"
      },
      "outputs": [],
      "source": [
        "model.add(tf.compat.v1.keras.layers.Dropout(0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Ijog-QxdNd"
      },
      "source": [
        "# 5- Create Output Layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RuBM8OBsxbkG"
      },
      "outputs": [],
      "source": [
        "# If Multiclassification It's Prefer Using Activation = tf.nn.softmax\n",
        "model.add(tf.compat.v1.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "# If Binary Classfication It's Prefer Used ==> activation = tf.nn.sigmoid or activation = tf.nn.tanh\n",
        "#model.add(tf.compat.v1.keras.layers.Dense(10, activation=tf.nn.sigmoid))\n",
        "#model.add(tf.compat.v1.keras.layers.Dense(10, activation=tf.nn.tanh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17MJ8wBd188C"
      },
      "source": [
        "# 6-Using Compile For Model Because Selection Parametrs For Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6Q0eT9dqyLR_"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#loss ='mes' ==> Used In Regression\n",
        "#loss = 'binary_crossentropy' ==> Used In Binary Classification\n",
        "#loss = 'categorical_crossentropy' ==> Used In Multiclassification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLQFpn153MiX"
      },
      "source": [
        "# 7- I Need Run NN Model By Using Model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AmN3XgDS2hzK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 1862, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5202, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 1862, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5202, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKF44g794l2M"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f14a256fa5d2abe453c482b40db541c720d938562dda362430172368847a78a4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
